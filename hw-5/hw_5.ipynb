{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d25acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c70f6",
   "metadata": {},
   "source": [
    "## Question 1: Install PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec9f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/01 21:44:23 WARN Utils: Your hostname, Alexs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.2.19 instead (on interface en0)\n",
      "22/03/01 21:44:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/Caskroom/miniforge/base/envs/pyspark_env/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/01 21:44:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b92a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f74c1",
   "metadata": {},
   "source": [
    "## Question 2: HVFHW February 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3877d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b213ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4c83c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,StringType,true),StructField(SR_Flag,StringType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418b04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d536202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").schema(schema).csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d69a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 2, 1, 0, 10, 40), dropoff_datetime=datetime.datetime(2021, 2, 1, 0, 21, 9), PULocationID=35, DOLocationID=39, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 2, 1, 0, 27, 23), dropoff_datetime=datetime.datetime(2021, 2, 1, 0, 44, 1), PULocationID=39, DOLocationID=35, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 2, 1, 0, 28, 38), dropoff_datetime=datetime.datetime(2021, 2, 1, 0, 38, 27), PULocationID=39, DOLocationID=91, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 2, 1, 0, 43, 37), dropoff_datetime=datetime.datetime(2021, 2, 1, 1, 23, 20), PULocationID=91, DOLocationID=228, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02872', pickup_datetime=datetime.datetime(2021, 2, 1, 0, 8, 42), dropoff_datetime=datetime.datetime(2021, 2, 1, 0, 17, 57), PULocationID=126, DOLocationID=250, SR_Flag=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8940c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fe686",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh fhvhv/2021/02/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f34b0",
   "metadata": {},
   "source": [
    "## Question 3: Count records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4ae978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed5c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e590019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pyspark_env/lib/python3.10/site-packages/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf28062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 10) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  367170|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    trips_data\n",
    "WHERE\n",
    "    CAST(pickup_datetime AS date) = '2021-02-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e165e5a",
   "metadata": {},
   "source": [
    "## Question 4: Longest trip for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e25c4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|         travel_time|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|2021-02-11 13:40:44|2021-02-12 10:39:44|INTERVAL '0 20:59...|\n",
      "+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pickup_datetime,\n",
    "    dropoff_datetime,\n",
    "    dropoff_datetime - pickup_datetime AS travel_time\n",
    "FROM\n",
    "    trips_data\n",
    "ORDER BY\n",
    "    travel_time DESC\n",
    "LIMIT 1;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c95dda",
   "metadata": {},
   "source": [
    "## Question 5: Most frequent dispatching_base_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a9a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|dispatching_base_num|most_frequent|\n",
      "+--------------------+-------------+\n",
      "|              B02510|      3233664|\n",
      "|              B02764|       965568|\n",
      "|              B02872|       882689|\n",
      "|              B02875|       685390|\n",
      "|              B02765|       559768|\n",
      "|              B02869|       429720|\n",
      "|              B02887|       322331|\n",
      "|              B02871|       312364|\n",
      "|              B02864|       311603|\n",
      "|              B02866|       311089|\n",
      "|              B02878|       305185|\n",
      "|              B02682|       303255|\n",
      "|              B02617|       274510|\n",
      "|              B02883|       251617|\n",
      "|              B02884|       244963|\n",
      "|              B02882|       232173|\n",
      "|              B02876|       215693|\n",
      "|              B02879|       210137|\n",
      "|              B02867|       200530|\n",
      "|              B02877|       198938|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    dispatching_base_num,\n",
    "    COUNT(dispatching_base_num) AS most_frequent\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0cd446",
   "metadata": {},
   "source": [
    "## Question 6: Most common locations pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82649677",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e00c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     266 taxi+_zone_lookup.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f351465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.option(\"header\", \"true\").csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e34cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(LocationID,StringType,true),StructField(Borough,StringType,true),StructField(Zone,StringType,true),StructField(service_zone,StringType,true)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c11795c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c002233",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('LocationID', types.IntegerType(), True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.TimestampType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "547b9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.option(\"header\", \"true\").schema(schema).csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f4fca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.registerTempTable('zones_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29c37fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 2, 4, 7, 50, 44), dropoff_datetime=datetime.datetime(2021, 2, 4, 8, 19, 59), PULocationID=181, DOLocationID=71, SR_Flag=None, Borough='Brooklyn', PUZone='Park Slope', service_zone=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = df.join(df_zones, df.PULocationID==df_zones.LocationID, how='left')\n",
    "df_join = df_join.withColumnRenamed('Zone', 'PUZone')\n",
    "df_join = df_join.drop('LocationID')\n",
    "df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6054ef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 2, 4, 7, 50, 44), dropoff_datetime=datetime.datetime(2021, 2, 4, 8, 19, 59), PULocationID=181, DOLocationID=71, SR_Flag=None, Borough='Brooklyn', PUZone='Park Slope', service_zone=None, Borough='Brooklyn', DOZone='East Flatbush/Farragut', service_zone=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = df_join.join(df_zones, df_join.DOLocationID==df_zones.LocationID, how='left')\n",
    "df_join = df_join.withColumnRenamed('Zone', 'DOZone')\n",
    "df_join = df_join.drop('LocationID')\n",
    "df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ca6e0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pyspark_env/lib/python3.10/site-packages/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_join.registerTempTable('fhvhv_zones_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7ab2eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|      pickup_dropoff|frequency|\n",
      "+--------------------+---------+\n",
      "|East New York/Eas...|    45041|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    CONCAT(COALESCE(PUZone, 'Unknown'), '/', COALESCE(DOZone, 'Unknown')) as pickup_dropoff,\n",
    "    COUNT(1) as frequency\n",
    "FROM\n",
    "    fhvhv_zones_data\n",
    "GROUP BY\n",
    "    pickup_dropoff\n",
    "ORDER BY\n",
    "    frequency DESC\n",
    "LIMIT 1;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4c0e3",
   "metadata": {},
   "source": [
    "## Bonus: Join type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a45bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
